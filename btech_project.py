# -*- coding: utf-8 -*-
"""btech-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cAOVf0vI1u6UzaHX9u1n0uLAD63K8Msw

# Prepocessing the data
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

cols="""duration,
protocol_type,
service,
flag,
src_bytes,
dst_bytes,
land,
wrong_fragment,
urgent,
hot,
num_failed_logins,
logged_in,
num_compromised,
root_shell,
su_attempted,
num_root,
num_file_creations,
num_shells,
num_access_files,
num_outbound_cmds,
is_host_login,
is_guest_login,
count,
srv_count,
serror_rate,
srv_serror_rate,
rerror_rate,
srv_rerror_rate,
same_srv_rate,
diff_srv_rate,
srv_diff_host_rate,
dst_host_count,
dst_host_srv_count,
dst_host_same_srv_rate,
dst_host_diff_srv_rate,
dst_host_same_src_port_rate,
dst_host_srv_diff_host_rate,
dst_host_serror_rate,
dst_host_srv_serror_rate,
dst_host_rerror_rate,
dst_host_srv_rerror_rate"""

columns=[]
for c in cols.split(','):
    if(c.strip()):
       columns.append(c.strip())

columns.append('target')
print(columns)
print(len(columns))

attacks_types = {
    'normal': 'normal',
    'back': 'dos',
    'buffer_overflow': 'u2r',
    'ftp_write': 'r2l',
    'guess_passwd': 'r2l',
    'imap': 'r2l',
    'ipsweep': 'probe',
    'land': 'dos',
    'loadmodule': 'u2r',
    'multihop': 'r2l',
    'neptune': 'dos',
    'nmap': 'probe',
    'perl': 'u2r',
    'phf': 'r2l',
    'pod': 'dos',
    'portsweep': 'probe',
    'rootkit': 'u2r',
    'satan': 'probe',
    'smurf': 'dos',
    'spy': 'r2l',
    'teardrop': 'dos',
    'warezclient': 'r2l',
    'warezmaster': 'r2l',
}


path = "../content/kddcup.data_10_percent.gz"
df = pd.read_csv(path,names=columns)

#Adding Attack Type column
df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])

df.head()

df['Attack Type'].value_counts()

"""# Visualizing the data"""

def bar_graph(feature):
    df[feature].value_counts().plot(kind="bar",color="red")

bar_graph('protocol_type')

plt.figure(figsize=(15,3))
bar_graph('service')

bar_graph('flag')

bar_graph('logged_in')

bar_graph('target')

bar_graph('Attack Type')

df.columns

"""# Removing highly correlated columns

*   List item
*   List item


"""

df = df.dropna(axis = 'columns') # drop columns with NaN

df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values

# corr = df.corr()
# Convert categorical variables into numerical representations using one-hot encoding
df_encoded = pd.get_dummies(df)

# Calculate the correlation matrix
corr_matrix = df_encoded.corr()

plt.figure(figsize=(15,12))

sns.heatmap(corr_matrix)

plt.show()

df.head()

#This variable is highly correlated with num_compromised and should be ignored for analysis.
#(Correlation = 0.9938277978738366)
df.drop('num_root',axis = 1,inplace = True)

#This variable is highly correlated with serror_rate and should be ignored for analysis.
#(Correlation = 0.9983615072725952)
df.drop('srv_serror_rate',axis = 1,inplace = True)

#This variable is highly correlated with rerror_rate and should be ignored for analysis.
#(Correlation = 0.9947309539817937)
df.drop('srv_rerror_rate',axis = 1, inplace=True)

#This variable is highly correlated with srv_serror_rate and should be ignored for analysis.
#(Correlation = 0.9993041091850098)
df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)

#This variable is highly correlated with rerror_rate and should be ignored for analysis.
#(Correlation = 0.9869947924956001)
df.drop('dst_host_serror_rate',axis = 1, inplace=True)

#This variable is highly correlated with srv_rerror_rate and should be ignored for analysis.
#(Correlation = 0.9821663427308375)
df.drop('dst_host_rerror_rate',axis = 1, inplace=True)

#This variable is highly correlated with rerror_rate and should be ignored for analysis.
#(Correlation = 0.9851995540751249)
df.drop('dst_host_srv_rerror_rate',axis = 1, inplace=True)

#This variable is highly correlated with dst_host_srv_count and should be ignored for analysis.
#(Correlation = 0.9736854572953938)
df.drop('dst_host_same_srv_rate',axis = 1, inplace=True)

df.head()

"""# Label encoding the features"""

#protocol_type feature mapping
pmap = {'icmp':0,'tcp':1,'udp':2}
df['protocol_type'] = df['protocol_type'].map(pmap)

#flag feature mapping
fmap = {'SF':0,'S0':1,'REJ':2,'RSTR':3,'RSTO':4,'SH':5 ,'S1':6 ,'S2':7,'RSTOS0':8,'S3':9 ,'OTH':10}
df['flag'] = df['flag'].map(fmap)

#attack type feature mapping
amap = {'dos':0,'normal':1,'probe':2,'r2l':3,'u2r':4}
df['Attack Type'] = df['Attack Type'].map(amap)

df.drop('service',axis = 1,inplace= True)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score

import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Concatenate, Add

df = df.drop(['target',], axis=1)
print(df.shape)

# Target variable and train set
Y = df[['Attack Type']]
X = df.drop(['Attack Type',], axis=1)

sc = MinMaxScaler()
X = sc.fit_transform(X)

# Split test and train data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33,
                                                    random_state=42)
print(X_train.shape, X_test.shape)
print(Y_train.shape, Y_test.shape)

df.to_csv("ids.csv", index=False)

pd.read_csv("ids.csv")

"""## Shallow Neural Network"""

shallow_model = Sequential([
    Dense(1024, input_dim=30, activation='relu'),
    Dropout(0.01),
    Dense(5, activation='softmax')
])

shallow_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

tf.keras.utils.plot_model(shallow_model, to_file="shallow_model.png", show_shapes=True)

shallow_model.fit(X_train, Y_train.values.ravel(), epochs=10, batch_size=32)

"""## Deep Neural Network"""

deep_model = Sequential([
    Dense(1024, input_dim=30, activation='relu'),
    Dropout(0.01),
    Dense(768, activation='relu'),
    Dropout(0.01),
    Dense(512, activation='relu'),
    Dropout(0.01),
    Dense(256, activation='relu'),
    Dropout(0.01),
    Dense(128, activation='relu'),
    Dropout(0.01),
    Dense(5, activation='softmax')
])

deep_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

tf.keras.utils.plot_model(deep_model, to_file="deep_model.png", show_shapes=True)

deep_model.fit(X_train, Y_train.values.ravel(), epochs=10, batch_size=32)

"""## Convolutional Neural Network"""

# cnn_model = Sequential([
#     Conv1D(64, 3, padding="same", activation="relu", input_shape=(30,1)),
#     MaxPooling1D(pool_size=(2)),
#     Flatten(),
#     Dense(128, activation="relu"),
#     Dropout(0.5),
#     Dense(5, activation="softmax")
# ])

inputs = Input(shape=(30, 1))
y = Conv1D(62, 3, padding="same", activation="relu", input_shape=(30,1))(inputs)
y = MaxPooling1D(pool_size=(2))(y)
y1 = Flatten()(y)

y = Dropout(0.5)(y)
y = Conv1D(62, 3, padding="same", activation="relu", input_shape=(30,1))(inputs)
y = MaxPooling1D(pool_size=(2))(y)
y2 = Flatten()(y)

y = Dropout(0.5)(y)
y = Conv1D(124, 3, padding="same", activation="relu", input_shape=(30,1))(inputs)
y = MaxPooling1D(pool_size=(2))(y)
y = Flatten()(y)
y = Dropout(0.5)(y)
y = Dense(256, activation="relu")(y)
y = Dropout(0.5)(y)
y = Dense(5, activation='softmax')(y)

y = Concatenate()([y, y1, y2])

outputs = Dense(5, activation='softmax')(y)
cnn_model = Model(inputs=inputs, outputs=outputs)

cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

tf.keras.utils.plot_model(cnn_model, to_file="cnn_model.png", show_shapes=True)

cnn_model.fit(X_train.reshape((-1,30,1)), Y_train.values.ravel(), epochs=10, batch_size=32)

"""# Testing the neural network"""

shallow_preds_train = shallow_model.predict(X_train)
shallow_test = shallow_model.predict(X_test)

deep_preds_train = deep_model.predict(X_train)
deep_test = deep_model.predict(X_test)

cnn_preds_train = cnn_model.predict(X_train.reshape((-1,30,1)))
cnn_test = cnn_model.predict(X_test.reshape((-1,30,1)))

print("SHALLOW NEURAL NETWORK")
print("Training Accuracy:", accuracy_score(Y_train, np.argmax(shallow_preds_train, axis=1)))
print("Testing Accuracy:", accuracy_score(Y_test, np.argmax(shallow_test, axis=1)))

print("DEEP NEURAL NETWORK")
print("Training Accuracy:", accuracy_score(Y_train, np.argmax(deep_preds_train, axis=1)))
print("Testing Accuracy:", accuracy_score(Y_test, np.argmax(deep_test, axis=1)))

print("CONVOLUTIONAL NEURAL NETWORK")
print("Training Accuracy:", accuracy_score(Y_train, np.argmax(cnn_preds_train, axis=1)))
print("Testing Accuracy:", accuracy_score(Y_test, np.argmax(cnn_test, axis=1)))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Function to print metrics for train and test sets
def print_metrics(model_name, y_true_train, y_pred_train, y_true_test, y_pred_test):
    print(f"\nMetrics for {model_name} Model:")

    # Train set
    print("\nTrain Set:")
    print("Accuracy:", accuracy_score(y_true_train, y_pred_train))
    print("Precision:", precision_score(y_true_train, y_pred_train, average='weighted'))
    print("Recall:", recall_score(y_true_train, y_pred_train, average='weighted'))
    print("F1-Score:", f1_score(y_true_train, y_pred_train, average='weighted'))
    print("Classification Report:\n", classification_report(y_true_train, y_pred_train))

    # Test set
    print("\nTest Set:")
    print("Accuracy:", accuracy_score(y_true_test, y_pred_test))
    print("Precision:", precision_score(y_true_test, y_pred_test, average='weighted'))
    print("Recall:", recall_score(y_true_test, y_pred_test, average='weighted'))
    print("F1-Score:", f1_score(y_true_test, y_pred_test, average='weighted'))
    print("Classification Report:\n", classification_report(y_true_test, y_pred_test))

# Predictions from the models
shallow_preds_train_labels = np.argmax(shallow_preds_train, axis=1)
shallow_test_labels = np.argmax(shallow_test, axis=1)

deep_preds_train_labels = np.argmax(deep_preds_train, axis=1)
deep_test_labels = np.argmax(deep_test, axis=1)

cnn_preds_train_labels = np.argmax(cnn_preds_train, axis=1)
cnn_test_labels = np.argmax(cnn_test, axis=1)

# Print metrics for each model
print_metrics("Shallow Neural Network", Y_train, shallow_preds_train_labels, Y_test, shallow_test_labels)
print_metrics("Deep Neural Network", Y_train, deep_preds_train_labels, Y_test, deep_test_labels)
print_metrics("Convolutional Neural Network", Y_train, cnn_preds_train_labels, Y_test, cnn_test_labels)

"""# More info"""

df.columns

"""![image.png](https://i.ibb.co/QH93r9g/Screenshot-from-2022-11-03-02-32-15.png)

![image.png](https://i.ibb.co/B3J7kSV/Screenshot-from-2022-11-03-02-24-30.png)


Table 4: Summarizes attack types and 4 different categories: (1)DoS (Denial of Service attacks), (2) R2L (Root to Local attacks), (3) U2R (User to Root attack), (4) Probe (Probing attacks).
"""